{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Parts of Speech Tagging\n",
    "---\n",
    "Group Name: Destiny's Child\n",
    "\n",
    "\n",
    "\n",
    "![speech](images/speech.jpg \"First slide\")\n",
    "\n",
    "\n",
    "- Miguel Romero Calvo\n",
    "- Jenny Kong\n",
    "- Louise Lai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Outline\n",
    "---\n",
    "\n",
    "What is POS tagging?\n",
    "    - Old approaches\n",
    "\n",
    "Machine Learning Solution\n",
    "    - Grid search\n",
    "    - Hyperparameter tuning\n",
    "\n",
    "Experimental approach with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is Part-Of-Speech tagging?\n",
    "\n",
    "![posttagging illustrated](images/posstaggingExample.jpeg \"Parts Of Speech Tagging\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Examples of part-of-speech tags \n",
    "---\n",
    "|  Tag  | Description|\n",
    "|-------| -----------|\n",
    "|CC\t|Coordinating conjunction|\n",
    "|CD\t|Cardinal number|\n",
    "|DT\t|Determiner|\n",
    "|EX\t|Existential there|\n",
    "|FW\t|Foreign word|\n",
    "|IN\t|Preposition or subordinating conjunction|\n",
    "|JJ\t|Adjective|\n",
    "|JJR|\tAdjective, comparative|\n",
    "|JJS|\tAdjective, superlative|\n",
    "|LS\t|List item marker|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is Part-Of-Speech tagging hard?\n",
    "\n",
    "\"They refuse to grant us a refuse permit.\"\n",
    "![Refuse](images/refuseBoth.png \"Refuse\")\n",
    "\n",
    "How do we know which one to tag?\n",
    "- refUSE (/rəˈfyo͞oz/) is a verb meaning “deny” \n",
    "- REFuse (/ˈrefˌyo͞os/) is a noun meaning “trash”\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why is Part-Of-Speech tagging hard?\n",
    "![Time Flies](images/timeflies.png \"Syntactic Ambiguity\")\n",
    "Ambiguity and context dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Old Approaches\n",
    "\n",
    "**Rule-based tagging**: <br>\n",
    "\n",
    "\"If word X is preceded by a determiner and followed by a noun, tag it as an adjective.\" <br>\n",
    "\n",
    "**Stochastic tagging**:\n",
    "\n",
    "\"The best tag for a given word is determined by the probability that it occurs with the n previous tags.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What we did\n",
    "1. A Machine Learning approach (KNN, DecisionTree, LogisticRegression)\n",
    "2. Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Show me the Data\n",
    "---\n",
    "\n",
    "Example of one line of data:\n",
    "\n",
    "![sample data line](images/sampleLine.png \"One line of data\")\n",
    "\n",
    "\n",
    "Numbers correspond to these tags:\n",
    "\n",
    "![POS classes](images/classes.png \"Our POS tag classes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Data\n",
    "----\n",
    "![word cloud of frequent words](images/freqwordcloud.png \"Word Cloud of Freuent Words\")\n",
    "![barplot of frequent words](images/wordBarplot.png \"Word Cloud of Freuent Words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data\n",
    "\n",
    "![charts of tags](images/tagsBotj.png \"Frequent Tags\")\n",
    "\n",
    "|#|POS|\n",
    "|---|---|\n",
    "|NNPS| Proper noun, plural|\n",
    "|PDT| Predeterminer|\n",
    "|JJS| Adjective, superlative|\n",
    "|JJ| Adjective|\n",
    "|JS| List item marker|\n",
    "|PRP| Personal pronoun|\n",
    "|CD| Cardinal number|\n",
    "|VBP| Verb, non-3rd person singular present|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Again, the goal is to accurately predict a tag for each word\n",
    "*tags: verb, adjective, noun, preposition etc.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capitals_inside': False,\n",
      " 'has_hyphen': False,\n",
      " 'is_all_caps': False,\n",
      " 'is_all_lower': False,\n",
      " 'is_capitalized': True,\n",
      " 'is_first': True,\n",
      " 'is_last': False,\n",
      " 'is_numeric': False,\n",
      " 'next_word': 'is',\n",
      " 'prefix-1': 'T',\n",
      " 'prefix-2': 'Th',\n",
      " 'prefix-3': 'Thi',\n",
      " 'prev_word': '',\n",
      " 'suffix-1': 's',\n",
      " 'suffix-2': 'is',\n",
      " 'suffix-3': 'his',\n",
      " 'word': 'This'}\n"
     ]
    }
   ],
   "source": [
    "# Step one: feature extraction\n",
    "import pprint \n",
    "def features(sentence, index):\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'is_capitalized': sentence[index][0].upper() == sentence[index][0],\n",
    "        'is_all_caps': sentence[index].upper() == sentence[index],\n",
    "        'is_all_lower': sentence[index].lower() == sentence[index],\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'has_hyphen': '-' in sentence[index],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        'capitals_inside': sentence[index][1:].lower() != sentence[index][1:]\n",
    "    }\n",
    " \n",
    "pprint.pprint(features(['This', 'is', 'a', 'sentence'], 0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train Test Split 75/25\n",
    "\n",
    "train: 26,975 lines\n",
    "\n",
    "test:   8,992 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Built a Pipeline and Grid Searched models & hypterparameters:\n",
    "\n",
    "1. Decision Tree Classifier <br>\n",
    "\n",
    "\n",
    "   \n",
    "2. K-NN Classifier <br>\n",
    "    \n",
    "\n",
    "\n",
    "3. Logistic Regression (*penalty, solver, multi_class*) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model Comparison\n",
    "---\n",
    "|Models|Training Time(sec)|Accuracy|F-Score|\n",
    "|---|---|---|---|\n",
    "|Base|-|0.1390|0.0001|\n",
    "|SVM|63.9|0.1395|0.2892|\n",
    "|KNN|15.3|0.8678|0.8786|\n",
    "|Decision Tree|3.5|0.9072|0.9069|\n",
    "|Tuned Decision Tree|3.4|0.9077|0.9065|\n",
    "|Logistic Regression|6.0|0.9286|0.9134|\n",
    "|Tuned Logistic Regression|7.2|0.9304|0.9222|\n",
    "\n",
    "- Perfomance on unseen data is excellent\n",
    "- Logistic Regression vs. Decision Trees are both very good (0.9077 v. 0.9304)\n",
    "- Decision Trees are faster, more interpretable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Model Comparison\n",
    "-----------\n",
    "\n",
    "![accuracy](images/AccurayGraph.png \"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experimental approach with Deep Learning\n",
    "\n",
    "<br>\n",
    "\n",
    "### Motivations:\n",
    "\n",
    "#### - Overcome a plateau. \n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"750\" height=\"312.0\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">immediately</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">close</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">relations</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,2.0 400.0,2.0 400.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en')\n",
    "doc = nlp(u\"Not immediately close relations\")\n",
    "displacy.render(doc, style='dep', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Experimental approach with Deep Learning\n",
    "\n",
    "<br>\n",
    "\n",
    "### Motivations:\n",
    "\n",
    "#### - Overcome the plateau. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Goals:\n",
    "\n",
    "#### 1. Experimenting a new approach with Transfer Learning and Deep Learning. \n",
    "\n",
    "#### 2. Contribute to the FastAI library.\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approach: ULMFiT\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Universal Languge Model Fine-tuning for Text classification, Howard et. al., May 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approach: ULMFiT\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Universal Languge Model Fine-tuning for Text classification, Howard et. al., May 2018.\n",
    "                                                       TRAINING DATASET\n",
    "##### Language Model\n",
    "<br>\n",
    "\n",
    "        Hello, how are _ --> you                       Wikipedia corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approach: ULMFiT\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Universal Languge Model Fine-tuning for Text classification, Howard et. al., May 2018.\n",
    "                                                                 TRAINING DATASET\n",
    "##### Language Model\n",
    "<br>\n",
    "\n",
    "        Hello, how are _ --> you                                 Wikipedia corpus\n",
    "\n",
    "##### Sentence Classification\n",
    "<br>\n",
    "\n",
    "       “The beauty of me is that I’m very rich.” --> Negative    -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Approach: ULMFiT\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Universal Languge Model Fine-tuning for Text classification, Howard et. al., May 2018.\n",
    "                                                         TRAINING DATASET\n",
    "##### Language Model\n",
    "<br>\n",
    "\n",
    "        Hello, how are _ --> you                         Wikipedia corpus\n",
    "\n",
    "##### Word Tagging\n",
    "<br>\n",
    "\n",
    "        Bob made a book --> noun, verb, article, noun    CoNLL 2003\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problems with the ULMFiT approach for this task\n",
    "\n",
    "Current pre-rules, tokenization (Spacy's default) and post-rules not suitable for this task.\n",
    "\n",
    "#### Example\n",
    "\n",
    "    'These aren't mine Jeorge !' --->  [xxmaj, these, are, n't, mine, xxmaj, xxunk, !]\n",
    "                        \n",
    "While we need:\n",
    "\n",
    "    'These aren't mine Jeorge !'---> [These, aren't, mine, Jeorge, !]\n",
    "                        \n",
    "So we could map each token to a label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implications of the approach\n",
    "\n",
    "\n",
    "With the `ULMFiT` approach:\n",
    "          \n",
    "         1. Pre-trained text treatment is problem dependent.\n",
    "\n",
    "With Deep Learning and `word2vec-type` embeddings:\n",
    "\n",
    "         1. Loosing known information when initialized.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In summary for this particular Task:\n",
    "\n",
    "* A ML approach with custom preprocesssing --> Good performance and relatively quick training.\n",
    "* A DL approach --> It can potentially achieve better performance and expensive in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you !"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
